{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16c882d2-800d-4c7e-9224-14e0f56375e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "# import annoy\n",
    "import pandas\n",
    "import transformers\n",
    "import numpy\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "import albumentations as A\n",
    "import cv2\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Declare an augmentation pipeline\n",
    "transform = A.Compose([\n",
    "    A.HorizontalFlip(p=0.3),\n",
    "    A.RandomBrightnessContrast(p=0.5),\n",
    "    A.GaussianBlur(p=0.3, blur_limit=(1, 3)),\n",
    "    A.GaussNoise(p=0.3, var_limit=(200.0, 300.0))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b216b90-f230-42c4-82f1-037248d8b654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_excel(\"data/output/Book1.xlsx\")\n",
    "# id2idx = {id: i for i, id in enumerate(data[\"id\"].unique())}\n",
    "# idx2id = {i: id for i, id in enumerate(data[\"id\"].unique())}\n",
    "\n",
    "# pickle.dump(id2idx, open(\"id2idx.pkl\", 'wb'))\n",
    "# pickle.dump(idx2id, open(\"idx2id.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce3c19e8-75e7-472c-b2c8-3bbd714f6429",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# label_folders = os.listdir(\"photos\")\n",
    "# bad_nums = 0\n",
    "# for lf in label_folders:\n",
    "#     path_ = \"photos/\" + lf + \"/1\"\n",
    "#     len_ = len(os.listdir(path_))\n",
    "#     if not len_:\n",
    "#         bad_nums += 1\n",
    "#         shutil.rmtree(\"photos/\" + lf) \n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc7c5715-27ca-4797-b12a-c1275d06ed23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_two_images(img_1, img_2):\n",
    "    dim = (175, 175)\n",
    "    img_1_ = cv2.resize(img_1, dim, interpolation = cv2.INTER_AREA)\n",
    "    img_2_ = cv2.resize(img_2, dim, interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "    concated_images = np.hstack([img_1_, img_2_])\n",
    "    \n",
    "    return concated_images\n",
    "\n",
    "def get_folders(path_to_label_folders):\n",
    "    res_folders = []\n",
    "    labels_folders = os.listdir(path_to_label_folders)#[:10]\n",
    "    for label_folder in labels_folders:\n",
    "        sample_folders = os.listdir(os.path.join(path_to_label_folders, label_folder))\n",
    "        for sample_folder in sample_folders:\n",
    "            res_folders.append(os.path.join(path_to_label_folders, label_folder, sample_folder))\n",
    "\n",
    "    return res_folders\n",
    "\n",
    "def get_model_n_processor(base_model_name, device=\"cpu\"):\n",
    "    model = timm.create_model(\n",
    "        base_model_name,\n",
    "        pretrained=True,\n",
    "        num_classes=num_classes,  # remove classifier nn.Linear\n",
    "    )\n",
    "    model.to(device)\n",
    "    \n",
    "    # get model specific transforms (normalization, resize)\n",
    "    data_config = timm.data.resolve_model_data_config(model)\n",
    "    processor = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "    print(f\"model: {base_model_name}, loaded\")\n",
    "    \n",
    "    return model, processor\n",
    "\n",
    "class CPCDataset(Dataset):\n",
    "    def __init__(self, label_folders, processor, train=True, transform=None):\n",
    "        self.label_folders = label_folders\n",
    "        self.processor = processor\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "        self.id2idx = id2idx\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.label_folders)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label_folder_path = self.label_folders[idx]\n",
    "\n",
    "        try:\n",
    "            img_1, img_2 = self.get_tow_imgs(label_folder_path)\n",
    "            id_ = int(label_folder_path.split(\"/\")[-2])\n",
    "            target = self.id2idx[id_]\n",
    "    \n",
    "            if self.train and np.random.randint(1,2) == 1:\n",
    "                img_1, img_2 = img_2, img_1\n",
    "    \n",
    "            if self.transform is not None:\n",
    "                try:\n",
    "                    transformed = transform(image=img_1)\n",
    "                    img_1 = transformed[\"image\"]\n",
    "            \n",
    "                    transformed = transform(image=img_2)\n",
    "                    img_2 = transformed[\"image\"]\n",
    "                except Exception:\n",
    "                    pass\n",
    "    \n",
    "            image = concat_two_images(img_1, img_2)\n",
    "            image = Image.fromarray(image)\n",
    "            \n",
    "            return self.processor(image), torch.tensor(target)\n",
    "        except Exception as e:\n",
    "            print(f\"Something goes wrong during reading data/preproc: {e}\")\n",
    "            return self.__getitem__(np.random.randint(0, len(self.label_folders)))\n",
    "\n",
    "    @staticmethod\n",
    "    def get_tow_imgs(label_folder_path):\n",
    "        img_names = os.listdir(label_folder_path)\n",
    "\n",
    "        if len(img_names) == 0:\n",
    "            raise IndexError(f\"No image in {label_folder_path}!\")\n",
    "            \n",
    "        img_1 = cv2.imread(f\"{label_folder_path}/{img_names[0]}\")\n",
    "        if len(img_names) > 1:\n",
    "            img_2 = cv2.imread(f\"{label_folder_path}/{img_names[1]}\")\n",
    "        else:\n",
    "            img_2 = cv2.imread(f\"{label_folder_path}/{img_names[0]}\")\n",
    "    \n",
    "        return img_1, img_2\n",
    "\n",
    "def train_epoch(model, loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    for iteration, data in tqdm(enumerate(loader), total=len(loader)):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        inputs, targets = data\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        pred_logits = model(inputs)#.flatten()\n",
    "        ce_loss = criterion(pred_logits, targets)\n",
    "        \n",
    "        ce_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "def eval_epoch(model, loader):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    trues = []\n",
    "    for iteration, data in tqdm(enumerate(loader), total=len(loader)):\n",
    "        inputs, targets = data\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        pred_logits = model(inputs)\n",
    "        \n",
    "        pred_labels = list(pred_logits.argmax(dim=1).detach().cpu().numpy())\n",
    "        \n",
    "        preds += pred_labels\n",
    "        trues += list(targets.detach().cpu().numpy())\n",
    "\n",
    "    return trues, preds\n",
    "\n",
    "def train_n_eval(model, train_loader, val_loader, criterion, optimizer, n_epochs):\n",
    "    for i in range(n_epochs):\n",
    "        train_epoch(model, train_loader, criterion, optimizer)\n",
    "        trues, preds = eval_epoch(model, val_loader)\n",
    "        accuracy = accuracy_score(trues, preds)\n",
    "        print(f\"epoch {i}: val accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1274e26-5e3b-4013-b4eb-9331642d40eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow_test = True # если нужно на небольшом кол-ве протестить\n",
    "path_to_label_folders = \"photos/\" # путь до папок с картинками\n",
    "base_model_name = 'mobilenetv3_large_100.ra_in1k' #  название предобученной модели с хагингфейс\n",
    "model_save_path = \"model_state_dict.pt\" # куда сохранить модель\n",
    "device = \"cuda\"\n",
    "n_epochs = 1\n",
    "lr = 1e-4\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd86a992-5177-4898-9dad-f54aff86281c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num imgs: 2000, num classes: 61656\n",
      "model: mobilenetv3_large_100.ra_in1k, loaded\n",
      "start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:17<00:00, 10.02it/s]\n",
      "100%|██████████| 75/75 [00:03<00:00, 24.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: val accuracy: 0.0\n",
      "training completed!\n",
      "Saving model!\n"
     ]
    }
   ],
   "source": [
    "all_label_folders = get_folders(path_to_label_folders)\n",
    "if workflow_test:\n",
    "    all_label_folders = all_label_folders[:1000]\n",
    "    \n",
    "id2idx = pickle.load(open(\"id2idx.pkl\", 'rb'))\n",
    "num_classes = len(id2idx)\n",
    "\n",
    "print(f\"num imgs: {len(all_label_folders)*2}, num classes: {num_classes}\")\n",
    "\n",
    "model, processor = get_model_n_processor(base_model_name, device=device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_label_folders, val_label_folders = train_test_split(all_label_folders, test_size=0.3, random_state=42)\n",
    "train_dataset = CPCDataset(train_label_folders, processor, train=True, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size, drop_last=True)\n",
    "\n",
    "val_dataset = CPCDataset(val_label_folders, processor, train=False, transform=None)\n",
    "val_loader = DataLoader(val_dataset, shuffle=False, batch_size=batch_size, drop_last=False)\n",
    "\n",
    "print(\"start training\")\n",
    "train_n_eval(model, train_loader, val_loader, criterion, optimizer, n_epochs)\n",
    "print(\"training completed!\")\n",
    "\n",
    "print(\"Saving model!\")\n",
    "torch.save(model.state_dict(), model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec74b4e9-b588-4eae-968f-f9f18e197382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: mobilenetv3_large_100.ra_in1k, loaded\n",
      "torch.Size([4, 1280])\n",
      "Check completed!\n"
     ]
    }
   ],
   "source": [
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "model, processor = get_model_n_processor(base_model_name, device=device)\n",
    "model.load_state_dict(torch.load(model_save_path))\n",
    "model.classifier = Identity()\n",
    "\n",
    "print(model(next(iter(val_loader))[0].to(device)).shape)\n",
    "print(\"Check completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
