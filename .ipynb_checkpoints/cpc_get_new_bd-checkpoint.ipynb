{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de8a7d8c-b346-4aef-9e70-0b9637c8be74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting annoy\n",
      "  Downloading annoy-1.17.3.tar.gz (647 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m647.5/647.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: annoy\n",
      "  Building wheel for annoy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for annoy: filename=annoy-1.17.3-cp310-cp310-linux_x86_64.whl size=75973 sha256=243a38fb02552ff9b0430d1afd8e37acf49468eabe51eef2053e370ae15d490c\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/64/8a/da/f714bcf46c5efdcfcac0559e63370c21abe961c48e3992465a\n",
      "Successfully built annoy\n",
      "Installing collected packages: annoy\n",
      "Successfully installed annoy-1.17.3\n"
     ]
    }
   ],
   "source": [
    "!pip install annoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2a31b4be-cce3-43d7-b531-f0cac678133b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "import annoy\n",
    "import pandas\n",
    "import transformers\n",
    "import numpy\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "import cv2\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from annoy import AnnoyIndex\n",
    "\n",
    "\n",
    "def get_tow_imgs(label_folder_path):\n",
    "    img_names = os.listdir(label_folder_path)\n",
    "\n",
    "    if len(img_names) == 0:\n",
    "        raise IndexError(f\"No image in {label_folder_path}!\")\n",
    "            \n",
    "    img_1 = cv2.imread(f\"{label_folder_path}/{img_names[0]}\")\n",
    "    if len(img_names) > 1:\n",
    "        img_2 = cv2.imread(f\"{label_folder_path}/{img_names[1]}\")\n",
    "    else:\n",
    "        img_2 = cv2.imread(f\"{label_folder_path}/{img_names[0]}\")\n",
    "    \n",
    "    return img_1, img_2\n",
    "    \n",
    "def concat_two_images(img_1, img_2):\n",
    "    dim = (175, 175)\n",
    "    img_1_ = cv2.resize(img_1, dim, interpolation = cv2.INTER_AREA)\n",
    "    img_2_ = cv2.resize(img_2, dim, interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "    concated_images = np.hstack([img_1_, img_2_])\n",
    "    \n",
    "    return concated_images\n",
    "\n",
    "def get_concated_img_from_label_folder(label_folder):\n",
    "    img_1, img_2 = get_tow_imgs(label_folder)\n",
    "    return concat_two_images(img_1, img_2)\n",
    "\n",
    "def get_folders(path_to_label_folders):\n",
    "    res_folders = []\n",
    "    labels_folders = os.listdir(path_to_label_folders)#[:10]\n",
    "    for label_folder in labels_folders:\n",
    "        sample_folders = os.listdir(os.path.join(path_to_label_folders, label_folder))\n",
    "        for sample_folder in sample_folders:\n",
    "            res_folders.append(os.path.join(path_to_label_folders, label_folder, sample_folder))\n",
    "\n",
    "    return res_folders\n",
    "    \n",
    "class AnnoyDB():\n",
    "    def __init__(self, f=1280, t=10):\n",
    "        self.f = f\n",
    "        self.t = t\n",
    "        self.vectore_storage = AnnoyIndex(f, 'angular')\n",
    "        self.idx_mapping_df = pd.DataFrame()\n",
    "        \n",
    "    def build_from_vectors(self, vectors):\n",
    "        for i in range(len(vectors)):\n",
    "            self.storage.add_item(i, vectors[i])\n",
    "\n",
    "    def build_from_label_folder(self, path_to_label_folders, model_embd):\n",
    "        rows = []\n",
    "        label_folders = get_folders(path_to_label_folders)\n",
    "        for i, label_folder in tqdm(enumerate(label_folders)):\n",
    "            try:\n",
    "                v = model_embd.get_embd(get_concated_img_from_label_folder(label_folder))\n",
    "                \n",
    "                self.vectore_storage.add_item(i, v)\n",
    "                rows.append({\n",
    "                    \"vector_idx\": i,\n",
    "                    \"numista_idx\": int(label_folder.split(\"/\")[-2])\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "        self.idx_mapping_df = pd.DataFrame(rows)\n",
    "    \n",
    "    def build_n_save(self, path_bd='test.ann', path_mapping_df=\"idx_mapping_df.csv\"):\n",
    "        self.vectore_storage.build(self.t)\n",
    "        self.vectore_storage.save(path_bd)\n",
    "        self.idx_mapping_df.to_csv(path_mapping_df, index=False)\n",
    "        \n",
    "    def load(self, vectore_storage_path='test.ann', df_path=\"data.csv\"):\n",
    "        self.vectore_storage = AnnoyIndex(self.f, 'angular')\n",
    "        self.vectore_storage.load(vectore_storage_path)\n",
    "        self.idx_mapping_df = pd.read_csv(df_path)\n",
    "        \n",
    "    def get_data_by_vector(self, embeding):\n",
    "        ni = self.vectore_storage.get_nns_by_vector(embeding, 1)[0]\n",
    "        res_dict = self.df.iloc[ni].to_dict()\n",
    "        \n",
    "        return res_dict\n",
    "        \n",
    "def get_model_n_processor(base_model_name, num_classes, device=\"cpu\"):\n",
    "    model = timm.create_model(\n",
    "        base_model_name,\n",
    "        pretrained=True,\n",
    "        num_classes=num_classes,  # remove classifier nn.Linear\n",
    "    )\n",
    "    model.to(device)\n",
    "    \n",
    "    # get model specific transforms (normalization, resize)\n",
    "    data_config = timm.data.resolve_model_data_config(model)\n",
    "    processor = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "    print(f\"model: {base_model_name}, loaded\")\n",
    "    \n",
    "    return model, processor\n",
    "\n",
    "class ModelEmbedSimple():\n",
    "    def __init__(self, model, processor, device=\"cuda\"):\n",
    "        self.processor = processor\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        \n",
    "    def get_embd(self, img):\n",
    "        inputs = Image.fromarray(img)\n",
    "        embding = self.model(self.processor(inputs).unsqueeze(0).to(self.device)).detach().cpu().numpy()[0]\n",
    "        embding /= np.linalg.norm(embding)\n",
    "\n",
    "        return embding\n",
    "        \n",
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fdbb581c-42da-480b-a685-5a6998bce677",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_name = 'mobilenetv3_large_100.ra_in1k'  #  название предобученной модели с хагингфейс\n",
    "model_path = \"../model_state_dict.pt\"  #  путь до обученной модели\n",
    "save_bd_path = \"data.ann\"  #  путь куда сохранять векторную бд\n",
    "path_to_label_folders = \"../photos\"  #  путь до папок с картинками\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "647d3ea9-1ef6-4a05-9902-96ba84cb43cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: mobilenetv3_large_100.ra_in1k, loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59498it [21:41, 45.70it/s]\n"
     ]
    }
   ],
   "source": [
    "model, processor = get_model_n_processor(base_model_name, 61656, device=device)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.classifier = Identity()\n",
    "model_embd = ModelEmbedSimple(model, processor)\n",
    "\n",
    "annoy_db = AnnoyDB(f=1280)\n",
    "annoy_db.build_from_label_folder(path_to_label_folders, model_embd)\n",
    "annoy_db.build_n_save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632f4f3a-4dfd-456c-a6d7-cbf3bc49df3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
